{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/28 18:41:55 INFO mlflow.tracking.fluent: Experiment with name 'homework_week_2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/yorgos/mlops-zoomcamp/Week_2/artifacts_local/2', creation_time=1716914515274, experiment_id='2', last_update_time=1716914515274, lifecycle_stage='active', name='homework_week_2', tags={}>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"homework_week_2\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.13.0\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 files in the output directory: ['dv.pkl', 'val.pkl', 'test.pkl', 'train.pkl']\n"
     ]
    }
   ],
   "source": [
    "output_files = os.listdir(\"output\")\n",
    "print(f\"There are {len(output_files)} files in the output directory: {output_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split: 2\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_EXPERIMENT_NAME = \"homework_week_2\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Get the experiment_id using the experiment name\n",
    "experiment = client.get_experiment_by_name(\"homework_week_2\")\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Get the run_id of the first (and only) experiment run\n",
    "runs = client.search_runs(experiment_ids=experiment_id)\n",
    "run_id = runs[0].info.run_id\n",
    "\n",
    "# Load the model from the local artifact store\n",
    "artifact_path = f\"mlartifacts/{experiment_id}/{run_id}/artifacts/model/model.pkl\"\n",
    "with open(artifact_path, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(f\"min_samples_split: {model.min_samples_split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI command: `mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root ./artifacts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation RMSE is 5.335419588556921\n"
     ]
    }
   ],
   "source": [
    "# Get the experiment_id using the experiment name\n",
    "experiment = client.get_experiment_by_name(\"random-forest-hyperopt\")\n",
    "\n",
    "# Get the run_id of the experiment with the best validation RMSE\n",
    "best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.rmse ASC\"]\n",
    ")[0]\n",
    "\n",
    "metric = client.get_metric_history(runs[0].info.run_id, \"rmse\")\n",
    "print(f\"The best validation RMSE is {best_run.data.metrics['rmse']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the best model on the test set is 5.567408012462019\n"
     ]
    }
   ],
   "source": [
    "experiment = client.get_experiment_by_name(\"random-forest-best-models\")\n",
    "best_run = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.test_rmse ASC\"]    \n",
    ")[0]\n",
    "\n",
    "best_run_id = best_run.info.run_id\n",
    "best_run_test_rmse = best_run.data.metrics[\"test_rmse\"]\n",
    "print(f\"The RMSE of the best model on the test set is {best_run_test_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
